# for Gilbreth
sinteractive -A pccr -p a10 -N1 -n1 --gpus-per-node=1 --cpus-per-task=28 --mem=165G -t 48:00:00 
# for Gautschi
sinteractive -A pccr -p ai -N1 -n1 --gpus-per-node=1 --cpus-per-task=14 --mem=128G -t 48:00:00



# shared backbone smallmodel 2 sessions
accelerate launch --num_processes=$((1 * 1)) \
--num_machines=1 \
--mixed_precision=fp16 train_shared_backbone.py \
--data_path=/depot/natallah/data/shourya/mindbridge/MindEyeV2/src/datasets \
--cache_dir=/depot/natallah/data/shourya/mindbridge/MindEyeV2/src/cache \
--model_name=shared_smallmodel_Trn4sVal1s \
--batch_size=3 \
--num_epochs=2 \
--num_sessions=4 \
--val_sessions=1 \
--hidden_dim=64 \
--n_blocks=2 \
--use_prior \
--prior_scale=30 \
--no-blurry_recon \
--clip_scale=1 \
--max_lr=3e-4 \
--mixup_pct=0.33 \
--no-use_image_aug \
--ckpt_saving \
--ckpt_interval=2 \
--wandb_log \
--wandb_project='mindbridge-pretraining'

--train_subjects=2 5 7 \